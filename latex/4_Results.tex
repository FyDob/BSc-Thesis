\section{Results}\label{ch:results}
During training, almost all $81$ trained models achieved a validation accuracy significantly above random guessing, except for the SRNN-2 models trained on the base and low LRD corpus, which scored $75.0\%$ and $50.4\%$ respectively. I have included them in the experiments regardless of their low validation accuracy, since it was unclear whether validation accuracy was a strong predictor for a network's performance on the experiment data. I present my results with regard to three focus points: First, the overall performance of different architectures with respect to which corpus they were trained on, then the individual model performances on each of the two experiments, and finally a closer look at classifications made by outlier networks - networks which drastically over- or underperformed in either of the experiments - with regards to word features.

\subsection{Architecture/Training Data}
\input{tab/results_compounded}
As can be seen in Table \ref{tab:perf_all}, none of the architectures consistently achieved an accuracy far above the random guessing baseline of $50.0\%$. However, there was still a notable difference in performance between architectures: on average, the GRU networks scored the highest on accuracy and precision, while the SRNN networks achieved the best recall and F1 score. With $51.5\%$, LSTMs scored an average accuracy right between SRNNs ($50.0\%$) and GRUs ($53.3\%$), but they underperformed in all other experiment measures.

Futhermore, the choice of training data had a notable effect on overall model performance: SRNNs and GRUs received a boost in performance in all measures when comparing the Base to the Low LRD models, elevating SRNNs from an accuracy below random guessing to $51.4\%$. While LSTMs lost $1.4\%$ in terms of accuracy, all other performance measures improved significantly for the Low LRD models. Training on the High LRD corpus aided SRNNs in terms of accuracy, precision and F1 score, but worsened accuracy, recall and F1 score for LSTMs and GRUs.

\subsection{Experiment 1: Long-Range Dependency}\label{resultsLRD}
Bla bla bla

\input{tab/results_LRD_base}

\input{tab/results_LRD_low}

\input{tab/results_LRD_high}

\subsection{Experiment 2: New Depths}\label{resultsND}

\input{tab/results_ND_base}

\input{tab/results_ND_low}

\input{tab/results_ND_high}
%\begin{figure}[h]
% 	\centering
%	\includegraphics[width=1.\textwidth, center]{fig/ACC_BEST_ND}
%	\caption[Experiment 2 - Accuracy by Index]{The predicted accuracy of the best-performing model of its architecture, calculated per character index. The baseline performance of $25\%$ is shown by the black dashed line. Note that the best High LRD and Baseline GRU models failed to learn $D_{2}$, despite their high accuracy.}
%\label{fig:DNAccuracyByIndex}
%\end{figure}
%Similarly to Experiment 1, several trends hold true for all models when inspecting the accuracy by character index for the best performing models. First, they continue to perform well above chance in all cases. Second, accuracy develops in $3$ distinct phases for this experiment: a sharp decline from character position $5$ to $14$, followed by a slower decline until character position $23$. Finally, accuracy decreases drastically, reaching its global minimum at character position $29$ and remaining there for the final character.
%\begin{figure}[h]
% 	\centering
%	\includegraphics[width=1.\textwidth, center]{fig/ND_overview}
%	\caption[Experiment 2 - Confusion Matrices]{The confusion matrices of the best performing RNN models, respective the corpus they were trained on.}
%\label{fig:DNConfusionMatrices}
%\end{figure}
%When considering the influence of training corpus properties on accuracy, the same pattern as in Experiment 1 emerges: the models trained on the Baseline or Low LRD corpus perform with equal accuracy ($34.36\%$), save for the Baseline GRU model ($50.94\%$). Again, a look at the model's confusion matrix shows it as unable to predict opening brackets at all (Figure \ref{fig:DNConfusionMatrices}). The same holds true for all models trained on the High LRD corpus. While they continue to outperform all other models in terms of accuracy (i.e. the SRNN with $8$ hidden units scores $67.40\%$), they fail the confusion matrix criterion and as such have failed to learn $D_{2}$.